{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ssd_model import DSOD300\n",
    "from ssd_data import InputGenerator\n",
    "from ssd_utils import PriorUtil\n",
    "from ssd_metric import confusion_matrix, plot_confusion_matrix, accuracy, evaluate_results\n",
    "from utils.model import load_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_voc import GTUtility\n",
    "gt_util = GTUtility('./data/VOC2007test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_coco import GTUtility\n",
    "gt_util = GTUtility('./data/COCO/', validation=True)\n",
    "gt_util = gt_util.convert_to_voc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DSOD300(input_shape=(300, 300, 3), num_classes=gt_util.num_classes); confidence_threshold = 0.275\n",
    "#model = DSOD300(input_shape=(600, 600, 3), num_classes=gt_util.num_classes); confidence_threshold = 0.35\n",
    "load_weights(model, './checkpoints/201808261035_dsod300fl_voccoco/weights.110.h5')\n",
    "\n",
    "prior_util = PriorUtil(model)\n",
    "\n",
    "inputs, data = gt_util.sample_batch(min(gt_util.num_samples, 10000), 0, input_size=model.image_size)\n",
    "#inputs, data = gt_util.sample_batch(min(gt_util.num_samples, 10000), 0, input_size=model.image_size, preserve_aspect_ratio=True)\n",
    "\n",
    "#gen = InputGenerator(gt_util, prior_util, min(gt_util.num_samples, 10000), model.image_size, augmentation=True)\n",
    "#inputs, data = next(gen.generate(encode=False))\n",
    "\n",
    "preds = model.predict(inputs, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = np.arange(0.05, 1, 0.05)\n",
    "\n",
    "fmes_grid = np.zeros((len(steps)))\n",
    "\n",
    "for i, t in enumerate(steps):\n",
    "    results = [prior_util.decode(p, t) for p in preds]\n",
    "    fmes = evaluate_results(data, results, gt_util, iou_thresh=0.5, max_dets=100, return_fmeasure=True)\n",
    "    fmes_grid[i] = fmes\n",
    "    print('threshold %.2f f-measure %.2f' % (t, fmes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_idx = np.argmax(fmes_grid)\n",
    "print(steps[max_idx], fmes_grid[max_idx])\n",
    "plt.figure(figsize=[12,6])\n",
    "plt.plot(steps, fmes_grid)\n",
    "plt.plot(steps[max_idx], fmes_grid[max_idx], 'or')\n",
    "plt.xticks(steps)\n",
    "plt.grid()\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('f-measure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confidence_threshold = 0.275 # pascal voc 2007 test\n",
    "#confidence_threshold = 0.550 # pascal voc 2012 test\n",
    "#confidence_threshold = 0.125 # ms coco test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall curve, mean Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [prior_util.decode(p, confidence_threshold=0.01, keep_top_k=400) for p in tqdm(preds)]\n",
    "evaluate_results(data, results, gt_util, iou_thresh=0.5, max_dets=100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test mAP\n",
    "                                     VOC07 VOC12 COCO\n",
    "SSD  300x300 VOC07+VOC12+COCO        0.651 0.659 0.421\n",
    "DSOD 300x300 VOC12+COCO              0.616 0.729 0.407\n",
    "DSOD 300x300 with data augmentation  0.605 \n",
    "DSOD 300x300 preserved aspect ratio  0.440 \n",
    "DSOD 600x600                         0.249 \n",
    "DSOD 600x600 preserved aspect ratio  0.140 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix of local predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [prior_util.decode(p, confidence_threshold) for p in tqdm(preds)]\n",
    "encoded_gt = [prior_util.encode(d) for d in tqdm(data)]\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    y_true = np.argmax(encoded_gt[i][:,4:], axis=1)\n",
    "    y_pred = np.argmax(preds[i][:,4:], axis=1)\n",
    "    #prior_object_idx = np.where(y_true)[0] # gt prior box contains object\n",
    "    prior_object_idx = np.where(y_true+y_pred)[0] # gt or prediction prior box contains object\n",
    "    y_true_all.extend(y_true[prior_object_idx])\n",
    "    y_pred_all.extend(y_pred[prior_object_idx])\n",
    "    \n",
    "#y_pred_all = [ 17 for i in y_pred_all]\n",
    "\n",
    "cm = confusion_matrix(y_true_all, y_pred_all, gt_util.num_classes)\n",
    "plot_confusion_matrix(cm, gt_util.classes, figsize=[12]*2)\n",
    "accuracy(y_true_all, y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in np.random.randint(0, len(inputs), 30):\n",
    "    plt.figure(figsize=[8]*2)\n",
    "    gt_util.plot_input(inputs[i])\n",
    "    #gt_util.plot_gt(data[i])\n",
    "    prior_util.plot_results(results=results[i], classes=gt_util.classes, gt_data=data[i], \n",
    "                            confidence_threshold=confidence_threshold)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "trained with focal loss and binary classifyers, 300x300\n",
    "prediction with image aspect ratio, 300x400, 400x300, data augmentation preserves aspect ratio if used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
